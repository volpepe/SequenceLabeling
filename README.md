# POSTagging

First assignement for the NLP course regarding neural architectures solving the task of Part-of-Speech tagging.

Members:
- Angelani Davide: https://github.com/qnozo - davide.angelani@studio.unibo.it
- Ceresini Marcello: https://github.com/MarcelloCeresini - marcello.ceresini@studio.unibo.it
- Cichetti Federico: https://github.com/volpepe - federico.cichetti@studio.unibo.it
- Ruberto Giuseppe: https://github.com/grubio234 - giuseppe.ruberto2@studio.unibo.it

---

Members:
- Angelani Davide: https://github.com/qnozo - davide.angelani@studio.unibo.it
- Ceresini Marcello: https://github.com/MarcelloCeresini - marcello.ceresini@studio.unibo.it
- Cichetti Federico: https://github.com/volpepe - federico.cichetti@studio.unibo.it
- Ruberto Giuseppe: https://github.com/grubio234 - giuseppe.ruberto2@studio.unibo.it

## Running the notebook

The trained weights for the models can be downloaded [here](https://drive.google.com/file/d/1J2K2k7ti66r4aoN8RVHgmmKgzcE9GJf6/view?usp=sharing)

The assignment explanation can be found [here](src/Assignment_1.ipynb) while our solution can be found in [the notebook](src/main.ipynb).

To run the notebook create a virtual environment (with either `conda` (eg. `conda create -n NLP python=3.8` or `venv` (`python3 -m venv .env`). activate it (`conda activate NLP` or `source .env/bin/activate` and download the [requirements](requirements.txt) using `python3 -m pip install -r requirements.txt`. Then, launch `jupyter-lab` or `jupyter-notebook` in the cloned folder and select the created environment as kernel to be used. If prompted to install `ipython`, install it.

Otherwise, the code can be run on [Google Colab](https://colab.research.google.com/): the above steps are not needed and a cloud GPU can be used for free.
